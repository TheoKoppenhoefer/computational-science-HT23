

\input{../Latex_Templates/Preamble_Report}

%%%%% TITLE PAGE

%\subject{, VT23}
\title{ Report for the Course Modelling in Computational Science, HT23 \\[1ex]
	  \large Project 1: The Potts model}
%\subtitle{}
\author{Theo KoppenhÃ¶fer}
\date{Lund \\[1ex] \today}

\addbibresource{bibliography.bib}

\usepackage{pythonhighlight}
\usepackage{pgfplots}
\graphicspath{{../Figures/}}

\pgfplotsset{
	compat=newest,
    every axis/.append style={
        axis y line=left,
        axis x line=bottom,
        scale only axis,
%    	max space between ticks=25pt,
        width=\textwidth,
        scaled ticks=true,
        axis line style={thick,-,>=latex, shorten >=-.4cm},
    		x tick label style={
		    /pgf/number format/precision=3
		}
    },
    every axis plot/.append style={thick},
    tick style={black, thick}
}

%%%%% The content starts here %%%%%%%%%%%%%


\begin{document}

\maketitle

\section{Introduction}

The following report is part of the first project of the Modelling in Computational Science course at Lund University, HT2023.
In the first project we implemented a Monte-Carlo simulation of the $q$-state Potts model.
The report and the Python implementation can be found online under \cite{Repository}

\section{The Potts model}

A state of the $q$-state Potts model of a $L\times L$ flat grid is given by a mapping
\begin{align*}
	s\colon \brk[c]{1,\dots,L}\times\brk[c]{1,\dots,L}\to\brk[c]{1,\dots,L}\,.
\end{align*}
One assigns this state an energy via
\begin{align*}
	E = -J\sum_{\substack{i, j\text{ neighbouring}\\ \text{grid points}}}\delta\brk*{s_i,s_j}
\end{align*}
where $\delta$ denotes the Kronecker-delta and $J=1$ is the coupling strength. As given in the problem setting we assume periodic boundary conditions on the grid.

\section{The algorithms}
\subsection{The Metropolis}
 
The steps for the Metropolis algorithm are given in figure \ref{alg:Metropolis}. A single iteration of this algorithm is performed by the function \pyth{MC_step_fast} in the implementation.

\begin{figure}
\centering
\begin{algorithm}[H]
\caption{Metropolis}
\label{alg:Metropolis}
\SetKwInOut{Input}{Input}

\Input{Initial data $s$, $L$, $T$, $q$}
\BlankLine
\For{$k=0,1,\dots$}{
	Pick a point on the grid.
	
	Propose a new random spin value for this point.
	
	Calculate the change of energy $\Delta E$ that this spin flip would cause.
	
	Accept this spin flip with probability $\min\brk[c]*{1,\exp(-\Delta E/T)}$.
}
\end{algorithm}
\end{figure}

\subsection{The heat-bath algorithm}

The steps of the heat-bath algorithm are given in figure \ref{alg:heat-bath}. In the implementation a single iteration is performed by the function \pyth{Gibbs_step}.

\begin{figure}
\centering
\begin{algorithm}[H]
\caption{Heat-bath}
\label{alg:heat-bath}
\SetKwInOut{Input}{Input}

\Input{Initial data $s$, $L$, $T$, $q$}
\BlankLine
\For{$k=0,1,\dots$}{
	Pick a point on the grid.
	
	Pick a spin value for this point with a probability given by the distribution
	\begin{align*}
		p(s_i) = C \exp\brk*{\frac{1}{T}\sum_{j\text{ neighbours }i}\delta\brk*{s_i,s_j}}\,.
	\end{align*}
	Here $C$ is a normalisation constant.
}
\end{algorithm}
\end{figure}

\section{The implementation}

\subsubsection{Determining when the Energy has plateaued}

The energy of the system takes some time $t_0$ to reach an equilibrium state. To determine $t_0$ we calculate in every step $i$ moving averages $\text{ma}_1$ and $\text{ma}_2$ over $n$ energies. The construction is shown in figure \ref{fi:movingAverages}. If we start in the hot state then the energy will tend to shrink until we reach an equilibrium. Hence we can use the condition
\begin{align}
	\text{ma}_2 \leq \text{ma}_1 \label{eq:equilCondition}
\end{align}
to determine $t_0$. If on the other hand we start in cold state the energy will in general increase and we have to reverse the inequality in equation \eqref{eq:equilCondition}. After reaching an equilibrium the simulation runs for a further \pyth{M_sampling=5000} steps. It is over these samples we take the mean and the variance.

\begin{figure}
\centering
\input{../Figures/explanationMovingAverages.pdf_tex}
\caption{Explanation of the moving averages.}
\label{fi:movingAverages}
\end{figure}

\subsubsection{Improving performance}
While simulating we run into performance issues due to the fact that Python is in general rather slow even with heavy use of Numpy. We resolved this issue with the help of Numba which precompiled functions and thus increased performance substantially. The downside is that the code becomes quite unestetic because Numba only supports some Python and Numpy features. In hindsight python seems to have been 

\section{The experiments}

\subsection{Distribution of energies in equilibrium}

In the following numerical experiment we set the grid size to $L=300$, the spin states to $q=10$ and the temperature to $T=10^2$. We then run the simulation until the system reached equilibrium. After that we varied the number of steps $M$ of the simulation and plotted the distribution of energies. The results can be seen in figures \ref{pl:Maxwell_distribution_0} to \ref{pl:Maxwell_distribution_3}. One sees that as $M$ increases the distribution approaches the Maxwell-Boltzmann distribution.

\begin{figure}
\begin{minipage}[b]{0.4\textwidth}
\centering
\input{../../Plots/Energies_maxwell_distribution_MC_step_fast_0.pgf}
\vspace*{-0.5cm}
\caption{For $M=10^5$}
\label{pl:Maxwell_distribution_0}
\end{minipage}
\hfill
\begin{minipage}[b]{0.4\textwidth}
\centering
\input{../../Plots/Energies_maxwell_distribution_MC_step_fast_1.pgf}
\vspace*{-0.5cm}
\caption{For $M=10^6$}
\label{pl:Maxwell_distribution_1}
\end{minipage}
\begin{minipage}[b]{0.4\textwidth}
\vspace*{1cm}
\centering
\input{../../Plots/Energies_maxwell_distribution_MC_step_fast_2.pgf}
\vspace*{-0.5cm}
\caption{For $M=4\cdot10^6$}
\label{pl:Maxwell_distribution_2}
\end{minipage}
\hfill
\begin{minipage}[b]{0.4\textwidth}
\centering
\input{../../Plots/Energies_maxwell_distribution_MC_step_fast_3.pgf}
\vspace*{-0.5cm}
\caption{For $M=10^7$}
\label{pl:Maxwell_distribution_3}
\end{minipage}
\end{figure}

\subsection{State plots}

In figures \ref{fi:Low_temp_state} to \ref{fi:High_temp_state} we can see that as the temperature increases the state of the system becomes more chaotic. For low temperatures there are larger patches of the same state which corresponds to a lower energy configuration. In the implementation one can see an animated version of the evolution of the system state.

\begin{figure}
\begin{minipage}{0.25\textwidth}
\centering
\graphicspath{{../../Plots/}}
\input{../../Plots/High_temp_state_10000.pgf}
\caption{State for temperature $T=0.1$.}
\label{fi:High_temp_state}
\end{minipage}
\hfill
\begin{minipage}{0.25\textwidth}
\centering
\graphicspath{{../../Plots/}}
\input{../../Plots/Medium_temp_state_10000.pgf}
\caption{State for temperature $T=1$.}
\label{fi:Medium_temp_state}
\end{minipage}
\hfill
\begin{minipage}{0.25\textwidth}
\centering
\graphicspath{{../../Plots/}}
\input{../../Plots/Low_temp_state_10000.pgf}
\caption{State for temperature $T=100$.}
\label{fi:Low_temp_state}
\end{minipage}
\end{figure}

\subsection*{Energies in dependence of the temperature}

\begin{figure}
\centering
\graphicspath{{../../Plots/}}
\input{../../Plots/energies_T_q_L500.pgf}
\end{figure}

\newpage
TODO:
\begin{itemize}
\item explain Metropolis algorithm
\item explain why we are interested in when the energy has plateaued.
\item explain Heat-bath algorithm
\item briefly explain implementation
\item sanity test hot vs. cold start
\item energy evolution for maxwell-distribution test
\item play around with phase transitions
\item phase transition test -> E-T plots and t0 plot
\item distribution based on energy
\item spell-check
\end{itemize}


\newpage
\section*{Bibliography}
%\nocite{*}
%Main source
%\printbibliography[heading=none, keyword={main}]
%\noindent Other sources
\printbibliography[heading=none, keyword={secondary}]

\end{document}
